{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Prediction View for the best Location\n",
    "\n",
    "This section attempts to predict where a suitable place might be to open a restaurant.<br>The existing crimes, restaurants and hot spot records are reused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# All the SciKit Learn Libraries Required\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "!pip install geopy  # uncomment this line if you haven't completed the Foursquare API lab\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import datetime\n",
    "from random import randint\n",
    "!pip install radar\n",
    "import radar\n",
    "\n",
    "# Use Folium to display the Maps for Visualisation\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import MarkerCluster\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "from sklearn.neighbors import DistanceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceBetween2Point(row):\n",
    "    kms = 6367\n",
    "    dist = DistanceMetric.get_metric('haversine')\n",
    "   \n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [row['LATITUDE'], row['LONGITUDE'], row['LOC_LATITUDE'], row['LOC_LONGITUDE']])\n",
    "\n",
    "    X = [[lat1, lon1], [lat2, lon2]]\n",
    "    \n",
    "    return kms * dist.pairwise(X)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the DataFrames\n",
    "\n",
    "Reuse the saved dataframes<br>\n",
    "We use only crime data from the year = 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the MCI in the DataFrame;We use only crime data from the year = 2018\n",
    "dfMCI = pd.read_csv('./data/Toronto_MCI.csv', parse_dates=['reportedda'])\n",
    "#dfMCI = dfMCI[dfMCI['reportedye'] == 2018]\n",
    "dfMCI = dfMCI.rename(columns={'Lat': 'LATITUDE', 'Long': 'LONGITUDE', 'reportedmo' : 'month', 'reportedho' : 'hour', 'reported_3': 'week_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMCI.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfDinaLoc = dfMCI[dfMCI['Division']==54]\n",
    "dfDinaLoc = dfMCI.copy()\n",
    "dfDinaLoc = dfDinaLoc.rename(columns={'Neighbourh': 'NAME'})\n",
    "\n",
    "df_predict = dfDinaLoc[['Division', 'NAME', 'LATITUDE', 'LONGITUDE']].copy()\n",
    "df_predict.drop_duplicates(keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDinaLoc.shape, df_predict.shape, dfMCI.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create One-hot encoding DataFrames for MCI\n",
    "\n",
    "Create a on hot Dataframe with the Latitude and Longitude, hour, day, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotCrime_dmy = dfMCI[['Division','LATITUDE', 'LONGITUDE']]\n",
    "\n",
    "df_onhotCrime_dmy = df_onhotCrime_dmy.join(pd.get_dummies(dfMCI.hour, prefix='h'))\n",
    "df_onhotCrime_dmy = df_onhotCrime_dmy.join(pd.get_dummies(dfMCI.week_day))\n",
    "df_onhotCrime_dmy = df_onhotCrime_dmy.join(pd.get_dummies(dfMCI.month))\n",
    "\n",
    "# copy df_onhotCrime_dmy as a train dataset; used below\n",
    "df_Train = df_onhotCrime_dmy.copy()\n",
    "\n",
    "# Finally add the ward column, copied from the original Primary Description column\n",
    "#df_onhotCrime_dmy['offence'] = dfMCI[['offence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotCrime_dmy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating crime data to calculate a prediction\n",
    "\n",
    "In this section we generate artificial crime data. The crimes will be split between an act `0` and no act `1`.<br>\n",
    "The newly created artificial record will be assigned to the restaurant and hot spot. The next step is to assign a random date.\n",
    "\n",
    "At the end a prediction should be made whether a crime will be committed in the desired place or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotCrime_dmy['art_crime'] = np.random.randint(0, 2, df_onhotCrime_dmy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotCrime_dmy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the copied on hot dataset as train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise df_onhotCrime_dmy\n",
    "df_Train = df_Train.astype(float)\n",
    "prep = preprocessing.StandardScaler()\n",
    "fit = prep.fit(df_Train)\n",
    "df_Train = fit.transform(df_Train)\n",
    "\n",
    "# as Result we use the artificial generated crime data column\n",
    "y_Train = df_onhotCrime_dmy.art_crime.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = RandomForestClassifier(n_estimators = 22, max_features = 'sqrt')\n",
    "ForestModel = FM.fit(df_Train, y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add to the Restaurant DataFrame a random visit (Year 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate random datetime (parsing date from str values) for each entry in the dataframe\n",
    "lstOfRndlstOfRndDates = []\n",
    "for i in range(0, df_predict.shape[0]):\n",
    "    date = radar.random_datetime(start='2018-01-01T00:00:00', stop='2018-12-31T23:59:59')\n",
    "    lstOfRndlstOfRndDates.append(date)\n",
    "    \n",
    "df_predict['next_crime_date'] = pd.to_datetime(lstOfRndlstOfRndDates, format='%m-%d-%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the same structure as the original MCI dataset\n",
    "df_predict['hour'] = df_predict['next_crime_date'].dt.hour\n",
    "df_predict['week_day'] = df_predict['next_crime_date'].dt.day_name()\n",
    "df_predict['reported_1'] = df_predict['next_crime_date'].dt.dayofweek + 1\n",
    "df_predict['month'] = df_predict['next_crime_date'].dt.month_name()\n",
    "df_predict['reportedye'] = df_predict['next_crime_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.reset_index(inplace=True)\n",
    "df_predict.drop('index', inplace=True, axis=1)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create One-hot encoding DataFrames for Restaurants\n",
    "\n",
    "Create a on hot Dataframe with the Latitude and Longitude, hour, day, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotDinas_dmy = df_predict[['Division','LATITUDE', 'LONGITUDE']]\n",
    "\n",
    "df_onhotDinas_dmy = df_onhotDinas_dmy.join(pd.get_dummies(df_predict.hour, prefix='h'))\n",
    "df_onhotDinas_dmy = df_onhotDinas_dmy.join(pd.get_dummies(df_predict.week_day))\n",
    "df_onhotDinas_dmy = df_onhotDinas_dmy.join(pd.get_dummies(df_predict.month))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onhotDinas_dmy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the prediction for a crime to a location\n",
    "\n",
    "A predictions value `0` is for possible crime at this location and `1` is for safe location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = ForestModel.predict(df_onhotDinas_dmy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Analysis\n",
    "\n",
    "In total 42 location were predicted as potentially safe locations to visit (19%) and 180 were classified as potentially susceptible to crime (81%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the predictions back to the datafame\n",
    "df_predict['prediction'] = yhat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.groupby('prediction').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation of Predictions\n",
    "\n",
    "2963 places were identified as potentially dangerous as to open a restaurant.\n",
    "To present the predictions, we will visualize the data again.\n",
    "\n",
    "We will look at the following 4 places:\n",
    "1. 1000 Pape Ave, Toronto, East York, Ontario, Kanada\n",
    "1. 100 hilton Avenue, Toronto, Ontario, Kanada\n",
    "1. 75 Spencer Avenue, Toronto, Ontario, Kanada\n",
    "1. 34 coulter Avenue, Toronto, Ontario, Kanada\n",
    "\n",
    "The Distance Dataframe is recreated again but this time all crimes are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Dina_places = pd.DataFrame({'Name': ['1000 Pape Ave, Toronto, East York, Ontario, Kanada',\n",
    "                  '100 hilton Avenue, Toronto, Ontario, Kanada',\n",
    "                  '75 Spencer Avenue, Toronto, Ontario, Kanada',\n",
    "                  '34 coulter Avenue, Toronto, Ontario, Kanada']})\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"Jupyter\")\n",
    "\n",
    "new_Dina_places['Location'] = new_Dina_places['Name'].apply(geolocator.geocode)\n",
    "new_Dina_places['Point'] = new_Dina_places['Location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "\n",
    "new_Dina_places.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist = pd.DataFrame()\n",
    "\n",
    "for name, point in zip(new_Dina_places.Name, new_Dina_places.Point):\n",
    "    print('Evaluate: ', name)\n",
    "    df_temp = dfMCI.copy()\n",
    "    df_temp['LOC_LATITUDE'] = point[0]\n",
    "    df_temp['LOC_LONGITUDE'] = point[1]\n",
    "    df_dist[name] = df_temp.apply(distanceBetween2Point, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 Pape Ave, Toronto, East York"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Dina_places.Name[0], new_Dina_places.Point[0][0], new_Dina_places.Point[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMCI_venue.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMCI_venue['dist'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Information for the first new places\n",
    "new_place_name = new_Dina_places.Name[0]\n",
    "new_place_latitude = new_Dina_places.Point[0][0]  \n",
    "new_place_longitude = new_Dina_places.Point[0][1] \n",
    "\n",
    "# Create the Folium Map\n",
    "heatmap = folium.Map(location=[new_place_latitude, new_place_longitude], zoom_start=16) \n",
    "\n",
    "# List comprehension to make out list of lists of Crimes\n",
    "heat_data = [[row['LATITUDE'], \n",
    "              row['LONGITUDE']] for index, row in dfMCI_venue.iterrows()]\n",
    "\n",
    "# Plot the crimes on the map\n",
    "HeatMap(heat_data,\n",
    "        min_opacity=0.5,\n",
    "        max_zoom=18, \n",
    "        max_val=1.0, \n",
    "        radius=20,\n",
    "        blur=30,\n",
    "        gradient=None,\n",
    "        overlay=True).add_to(heatmap)\n",
    "\n",
    "# Add the Venue to the Map\n",
    "folium.Marker(\n",
    "    location=[new_place_latitude, new_place_longitude],\n",
    "    popup=new_place_name,\n",
    "    icon=folium.Icon(color='blue', icon='info-sign')\n",
    ").add_to(heatmap)\n",
    "\n",
    "heatmap.save('./data/heatNewPlace1_map.html')\n",
    "\n",
    "# Display the map\n",
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
